---
title: "Bootstrapping"
output: github_document
---

```{r setup}
library(tidyverse)
library(viridis)

library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE, 
  fig.width = 8, 
  fig.height = 6, 
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "virids"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Bootstrapping 

* idea is to mimic repeated sampling with the one sample you have

* your sample is drawn at random from your population

** you'd like to draw more samples but can't

** so you draw a bootstrap sample from one sample you have (sample with replacement)

** the bootstrap sample has the same size as the original sample and is drawn with replacement 

** analyze this sample using whatever appraoch you want to apply 

** repeat 

* the repeated sampling framework often provides useful theoretical results under certain assumptions and/or asymptotics

** sample means follow a known distribution
** regression coefficients follow a known distribituion 
** ORs follow a known distribution 

* if assumptions aren't met - or sample isn't large enough for asymptotics, you can't use "known distribution" 

* bootstrapping gets back to repeated sampling, and uses empirical rather than theoretical distribution of your statistic of interest

Coding the bootstrap

* natural application of iterative tools

* write function (or functions) to: 
** draw a sample with replacement
** analyze the sample
** return object of interest

* repeat process many times

* keeping track of the bootstrap samples, analysis, and results in a single data frame that organizes the process and prevents mistakes 

* use list columns 


Bootstrapping vs. cross-validation

* similar

* get lots of data sets, run regression, results

* bootstrapping
** inference on some model parameter (CI for regression coefficient but don't trust usual statistics machinery, or CI for correlation that is close to 1)
** can't trust normal thing that you would do
** inference on some parameter or inference on some model componeent (sometimes p-value)
** here is the model - how to put CI on this thing, how to do....

* cross validation
** how well this model works on different data set
** both looking at one data set and thinking about if extended to whole population
** prediction accuracy - compare 2 models and see which ones is better (without p-values, hypothisis test)